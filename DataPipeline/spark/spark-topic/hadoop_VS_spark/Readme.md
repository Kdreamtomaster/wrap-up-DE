# Apache Hadoop vs Apache Spark 비교 및 장단점

Apache Hadoop과 Apache Spark는 모두 대규모 데이터를 처리하기 위한 분산 데이터 처리 프레임워크입니다. 이 문서에서는 두 기술의 주요 특징, 차이점 및 각각의 장단점을 비교하여 정리하였습니다.

---

## 1. 주요 특징 비교

| 항목              | **Apache Hadoop**                            | **Apache Spark**                             |
|-------------------|---------------------------------------------|---------------------------------------------|
| **주요 구성 요소** | HDFS, MapReduce, YARN                       | RDD, DataFrame, DAG, Spark SQL              |
| **데이터 처리 방식**| 배치 처리 중심                              | 배치 및 스트리밍 처리 모두 지원              |
| **속도**          | 디스크 기반 I/O로 속도가 비교적 느림        | 인메모리 처리를 통해 빠른 데이터 처리 가능    |
| **유연성**        | 주로 배치 처리에 적합                       | 스트리밍, SQL, 머신러닝 등 다양한 처리 가능  |
| **확장성**        | 높은 확장성 제공                            | 높은 확장성 제공                            |
| **사용 언어**      | Java 기반                                    | Python, Scala, Java, R 등 다중 언어 지원      |

---

## 2. Apache Hadoop의 장단점

### 장점
1. **안정성 및 신뢰성**  
   - HDFS는 데이터를 분산 저장하고 복제하여 데이터 유실을 방지.
   - 노드 장애 발생 시에도 데이터 복구 가능.
   
2. **대규모 데이터 처리**  
   - 페타바이트 단위의 데이터를 처리할 수 있는 강력한 확장성 제공.

3. **오랜 검증과 커뮤니티 지원**  
   - 오랜 기간 동안 다양한 대규모 프로젝트에서 사용되어 안정성이 높음.
   - 활발한 커뮤니티와 풍부한 문서 제공.

4. **저비용 데이터 스토리지**  
   - HDFS는 저비용의 하드웨어를 활용해 대규모 데이터를 저장할 수 있음.

### 단점
1. **속도 문제**  
   - 디스크 기반 I/O로 인해 데이터 처리 속도가 느림.
   - MapReduce의 반복 작업에서 오버헤드가 발생.

2. **실시간 데이터 처리 부족**  
   - 실시간 스트리밍 데이터 처리가 어렵고 배치 처리에만 초점이 맞춰져 있음.

3. **유연성 부족**  
   - SQL, 머신러닝, 그래프 처리 등 다양한 데이터 처리에 적합하지 않음.

4. **사용 복잡성**  
   - Java 기반으로 설계되어 설정 및 유지 관리가 복잡.

---

## 3. Apache Spark의 장단점

### 장점
1. **빠른 데이터 처리**  
   - 인메모리 처리 방식을 사용하여 디스크 기반 처리보다 훨씬 빠름.
   - DAG(Directed Acyclic Graph)를 기반으로 효율적인 작업 스케줄링 가능.

2. **다양한 데이터 처리**  
   - 배치 처리뿐만 아니라 실시간 스트리밍 처리, SQL 처리, 머신러닝 및 그래프 데이터 분석 지원.

3. **유연한 프로그래밍 인터페이스**  
   - Python, Scala, Java, R 등의 다양한 언어를 지원하여 개발자가 익숙한 언어로 작업 가능.

4. **확장성**  
   - 클러스터 기반으로 확장 가능하며, 분산 데이터 처리에 최적화.

5. **머신러닝 및 그래프 분석 지원**  
   - MLlib 및 GraphX 라이브러리를 통해 머신러닝 및 그래프 분석 작업이 가능.

### 단점
1. **비용 문제**  
   - Spark는 주로 메모리를 사용하므로 하드웨어 비용이 상대적으로 높음.

2. **복잡성**  
   - 사용자가 데이터 파이프라인을 효과적으로 설계하지 않으면 메모리 부족 등의 문제가 발생할 수 있음.

3. **HDFS 의존성**  
   - Spark 자체로는 데이터 저장 기능이 없으며, 데이터 저장을 위해 HDFS나 다른 스토리지 시스템이 필요.

4. **초기 학습 곡선**  
   - DAG 및 RDD 개념에 익숙해져야 하므로 초기 학습 곡선이 가파를 수 있음.

---

## 4. 적합한 사용 사례

### Apache Hadoop
- 대규모 배치 처리 작업이 주요 요구사항인 경우
- 안정적이고 저렴한 데이터 저장소가 필요한 경우
- 실시간 처리가 필요 없는 로그 분석 또는 데이터 백업 작업

### Apache Spark
- 실시간 데이터 처리와 분석이 필요한 경우
- 머신러닝 파이프라인 또는 그래프 분석 작업을 통합적으로 처리하려는 경우
- 속도가 중요한 대규모 데이터 처리 작업

---

## 5. 결론

Apache Hadoop과 Apache Spark는 각각의 강점이 있으며, 사용 사례에 따라 적합한 기술을 선택해야 합니다.

- **Hadoop**은 데이터 저장 및 배치 처리에 강점을 가지고 있으며, 안정성과 저렴한 데이터 저장 비용을 제공합니다.
- **Spark**는 인메모리 처리를 통한 속도, 다양한 데이터 처리 옵션, 실시간 스트리밍 처리에 강점을 가지고 있습니다.

두 기술은 상호보완적으로 사용될 수도 있습니다. 예를 들어, HDFS를 데이터 저장소로 사용하고 Spark를 데이터 처리 엔진으로 사용하는 방식이 일반적입니다.
