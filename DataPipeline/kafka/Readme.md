# 데이터 파이프라인에서 Apache Kafka를 사용한 이유

Apache Kafka는 대규모 데이터 파이프라인 환경에서 높은 처리량, 확장성, 내결함성, 실시간 데이터 처리 요구사항을 충족시키는 데 적합한 메시징 시스템입니다. 이 문서에서는 프로젝트에서 Kafka를 선택한 이유를 정리하였습니다.

---

## 1. 높은 처리량과 낮은 지연 시간
Kafka는 초당 수백만 건의 메시지를 처리할 수 있는 높은 처리량과 낮은 지연 시간을 제공합니다.  
이를 통해 데이터 스트림 처리, 로그 집계, 이벤트 중심 아키텍처에서 빠르고 안정적인 데이터 전송이 가능합니다.

---

## 2. 비동기 통신 및 느슨한 결합 구조
Kafka는 발신자(Producer)와 수신자(Consumer)가 직접 연결되지 않아도 되는 **느슨한 결합** 구조를 지원합니다.  
이를 통해:
- 서비스 간 독립적인 확장성 확보
- 장애 상황에서도 안정적인 데이터 처리
- 비동기 통신 방식으로 효율적인 데이터 처리

---

## 3. 중앙화된 데이터 흐름
Kafka는 모든 데이터와 이벤트를 중앙에서 관리할 수 있도록 도와줍니다.
- 데이터 흐름의 중앙화를 통해 복잡한 End-to-End 연결 구조를 단순화
- 다양한 시스템이 동일한 이벤트를 소비할 수 있어 데이터 활용도 극대화

---

## 4. 내구성과 데이터 보존
Kafka는 메시지를 메모리가 아닌 디스크에 **영구 저장**하므로 장애 상황에서도 데이터가 유실되지 않습니다.  
이로 인해:
- 데이터 파이프라인의 신뢰성 확보
- 과거 데이터 재처리 가능

---

## 5. 분산 아키텍처와 확장성
Kafka는 브로커, 파티션, 컨슈머 그룹을 통해 분산 환경에서 높은 확장성을 제공합니다.
- 다수의 브로커로 구성된 Kafka 클러스터는 대규모 데이터 처리 가능
- 데이터 부하 분산을 통한 유연한 확장성

---

## 6. Pull 기반 메시지 소비
Kafka는 컨슈머가 브로커로부터 데이터를 가져오는 **Pull 방식**을 사용합니다.
- 컨슈머는 자신의 처리 속도에 맞게 데이터를 소비
- 브로커 과부하 방지
- 안정적인 데이터 처리 환경 제공

---

## 📌 예시 응용 시나리오
1. **로그 집계**  
   - 여러 서비스에서 발생하는 로그 데이터를 Kafka를 통해 중앙화
   - 이를 Logstash나 Elasticsearch로 전달하여 분석

2. **실시간 데이터 분석**  
   - 새로운 데이터 이벤트가 발생할 때 Kafka에서 데이터를 소비
   - 실시간 대시보드 업데이트 수행

3. **알림 시스템**  
   - 특정 조건에 맞는 이벤트를 Kafka로 전달하여 알림 트리거

---

## 결론
Apache Kafka는 높은 처리량, 내구성, 확장성을 제공하며, 비동기적이고 중앙화된 메시징 시스템으로 데이터 파이프라인을 단순화하고 신뢰성을 확보하는 데 기여합니다.  
이를 통해 복잡한 데이터 아키텍처 문제를 해결하고 안정적인 데이터 흐름을 보장할 수 있습니다.
